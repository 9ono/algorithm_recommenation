{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /Users/imac/anaconda3/envs/hi/lib/python3.7/site-packages (0.9.1)\r\n",
      "Requirement already satisfied: pybind11>=2.2 in /Users/imac/anaconda3/envs/hi/lib/python3.7/site-packages (from fasttext) (2.4.3)\r\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /Users/imac/anaconda3/envs/hi/lib/python3.7/site-packages (from fasttext) (41.4.0)\r\n",
      "Requirement already satisfied: numpy in /Users/imac/anaconda3/envs/hi/lib/python3.7/site-packages (from fasttext) (1.17.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "\n",
    "class ImplementFastText:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Init class vars.\"\"\"\n",
    "        self.model = ''\n",
    "        self.precision = 0.0\n",
    "        self.recall = 0.0\n",
    "        self.f_score = 0.0\n",
    "\n",
    "    def load_model(self, model):\n",
    "        \"\"\"Load pre-trained model.\"\"\"\n",
    "        #self.model = fasttext.load_model('./model.bin')\n",
    "        self.model = model\n",
    "        \n",
    "    def score(self):\n",
    "        \"\"\"Get classification scores.\"\"\"\n",
    "        self.model_score = self.model.test('./Data/fasttext/test.txt')\n",
    "\n",
    "        num_samples = self.model_score[0]\n",
    "        self.precision = self.model_score[1]\n",
    "        self.recall = self.model_score[2]\n",
    "\n",
    "        self.f_score = 2 * ((self.precision * self.recall) /\n",
    "                            (self.precision + self.recall))\n",
    "\n",
    "        return {\n",
    "            'num_samples': num_samples,\n",
    "            'precision': round(self.precision, 3),\n",
    "            'recall': round(self.recall, 3),\n",
    "            'f_score': round(self.f_score, 3)\n",
    "        }\n",
    "\n",
    "    def predict(self, question, num_tags=5):\n",
    "        \"\"\"Get predicted tags with probability scores.\"\"\"\n",
    "        self.result = self.model.predict(question, k=num_tags)\n",
    "\n",
    "        tags = list(map(\n",
    "            lambda tag: tag.replace('__label__', ''), self.result[0][0]))\n",
    "        probability_score = list(map(\n",
    "            lambda score: round(score, 3), self.result[1][0]))\n",
    "\n",
    "        predicted_tags = dict(zip(tags, probability_score))\n",
    "        #predicted_tags.pop('')\n",
    "\n",
    "        return predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_predictions(question, no_of_tags):\n",
    "    \"\"\"Get predicted tags and score of the models.\n",
    "\n",
    "    By already loading the trained model and invoking fasttext methods.\n",
    "    \"\"\"\n",
    "    ft_obj = ImplementFastText()\n",
    "    ft_obj.load_model()\n",
    "    result = ft_obj.predict([question], num_tags=no_of_tags)\n",
    "    score = ft_obj.score()\n",
    "\n",
    "    return result, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [x*0.1 for x in range(1,11)]     ## 0.1 ~ 1.0 0.1 단위로\n",
    "epochs = [x for x in range(5, 55, 5)]   ## 5 ~ 50\n",
    "ngrams = [x for x in range(1,6)] # 1 ~ 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for lr in learning_rate:\n",
    "    for epoch in epochs:\n",
    "        for ngram in ngrams:\n",
    "            model = fasttext.train_supervised(input=\"./Data/fasttext/train.txt\", lr=lr,\\\n",
    "                                               epoch=epoch, wordNgrams=ngram, bucket=200000, dim=50, loss='ova')\n",
    "            ft_obj = ImplementFastText()\n",
    "            ft_obj.load_model(model)\n",
    "            score = ft_obj.score()\n",
    "            tmp = [lr, epoch, ngram, score]\n",
    "            scores.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1, 5, 1, {'num_samples': 859, 'precision': 0.389, 'recall': 0.165, 'f_score': 0.232}]\n",
      "[0.1, 5, 2, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 5, 3, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 5, 4, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 5, 5, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 10, 1, {'num_samples': 859, 'precision': 0.522, 'recall': 0.221, 'f_score': 0.311}]\n",
      "[0.1, 10, 2, {'num_samples': 859, 'precision': 0.384, 'recall': 0.163, 'f_score': 0.229}]\n",
      "[0.1, 10, 3, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 10, 4, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 10, 5, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 15, 1, {'num_samples': 859, 'precision': 0.603, 'recall': 0.256, 'f_score': 0.359}]\n",
      "[0.1, 15, 2, {'num_samples': 859, 'precision': 0.46, 'recall': 0.195, 'f_score': 0.274}]\n",
      "[0.1, 15, 3, {'num_samples': 859, 'precision': 0.378, 'recall': 0.16, 'f_score': 0.225}]\n",
      "[0.1, 15, 4, {'num_samples': 859, 'precision': 0.333, 'recall': 0.141, 'f_score': 0.198}]\n",
      "[0.1, 15, 5, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.1, 20, 1, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.1, 20, 2, {'num_samples': 859, 'precision': 0.523, 'recall': 0.222, 'f_score': 0.311}]\n",
      "[0.1, 20, 3, {'num_samples': 859, 'precision': 0.447, 'recall': 0.19, 'f_score': 0.266}]\n",
      "[0.1, 20, 4, {'num_samples': 859, 'precision': 0.374, 'recall': 0.159, 'f_score': 0.223}]\n",
      "[0.1, 20, 5, {'num_samples': 859, 'precision': 0.333, 'recall': 0.141, 'f_score': 0.198}]\n",
      "[0.1, 25, 1, {'num_samples': 859, 'precision': 0.704, 'recall': 0.299, 'f_score': 0.42}]\n",
      "[0.1, 25, 2, {'num_samples': 859, 'precision': 0.567, 'recall': 0.24, 'f_score': 0.338}]\n",
      "[0.1, 25, 3, {'num_samples': 859, 'precision': 0.485, 'recall': 0.206, 'f_score': 0.289}]\n",
      "[0.1, 25, 4, {'num_samples': 859, 'precision': 0.444, 'recall': 0.188, 'f_score': 0.264}]\n",
      "[0.1, 25, 5, {'num_samples': 859, 'precision': 0.369, 'recall': 0.157, 'f_score': 0.22}]\n",
      "[0.1, 30, 1, {'num_samples': 859, 'precision': 0.705, 'recall': 0.299, 'f_score': 0.42}]\n",
      "[0.1, 30, 2, {'num_samples': 859, 'precision': 0.608, 'recall': 0.258, 'f_score': 0.362}]\n",
      "[0.1, 30, 3, {'num_samples': 859, 'precision': 0.524, 'recall': 0.222, 'f_score': 0.312}]\n",
      "[0.1, 30, 4, {'num_samples': 859, 'precision': 0.466, 'recall': 0.198, 'f_score': 0.277}]\n",
      "[0.1, 30, 5, {'num_samples': 859, 'precision': 0.435, 'recall': 0.185, 'f_score': 0.259}]\n",
      "[0.1, 35, 1, {'num_samples': 859, 'precision': 0.696, 'recall': 0.295, 'f_score': 0.415}]\n",
      "[0.1, 35, 2, {'num_samples': 859, 'precision': 0.645, 'recall': 0.274, 'f_score': 0.384}]\n",
      "[0.1, 35, 3, {'num_samples': 859, 'precision': 0.56, 'recall': 0.238, 'f_score': 0.334}]\n",
      "[0.1, 35, 4, {'num_samples': 859, 'precision': 0.504, 'recall': 0.214, 'f_score': 0.3}]\n",
      "[0.1, 35, 5, {'num_samples': 859, 'precision': 0.459, 'recall': 0.195, 'f_score': 0.273}]\n",
      "[0.1, 40, 1, {'num_samples': 859, 'precision': 0.689, 'recall': 0.292, 'f_score': 0.411}]\n",
      "[0.1, 40, 2, {'num_samples': 859, 'precision': 0.68, 'recall': 0.288, 'f_score': 0.405}]\n",
      "[0.1, 40, 3, {'num_samples': 859, 'precision': 0.593, 'recall': 0.251, 'f_score': 0.353}]\n",
      "[0.1, 40, 4, {'num_samples': 859, 'precision': 0.526, 'recall': 0.223, 'f_score': 0.313}]\n",
      "[0.1, 40, 5, {'num_samples': 859, 'precision': 0.477, 'recall': 0.202, 'f_score': 0.284}]\n",
      "[0.1, 45, 1, {'num_samples': 859, 'precision': 0.685, 'recall': 0.29, 'f_score': 0.408}]\n",
      "[0.1, 45, 2, {'num_samples': 859, 'precision': 0.689, 'recall': 0.292, 'f_score': 0.411}]\n",
      "[0.1, 45, 3, {'num_samples': 859, 'precision': 0.622, 'recall': 0.264, 'f_score': 0.37}]\n",
      "[0.1, 45, 4, {'num_samples': 859, 'precision': 0.554, 'recall': 0.235, 'f_score': 0.33}]\n",
      "[0.1, 45, 5, {'num_samples': 859, 'precision': 0.511, 'recall': 0.217, 'f_score': 0.304}]\n",
      "[0.1, 50, 1, {'num_samples': 859, 'precision': 0.688, 'recall': 0.292, 'f_score': 0.41}]\n",
      "[0.1, 50, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.1, 50, 3, {'num_samples': 859, 'precision': 0.64, 'recall': 0.272, 'f_score': 0.381}]\n",
      "[0.1, 50, 4, {'num_samples': 859, 'precision': 0.58, 'recall': 0.246, 'f_score': 0.345}]\n",
      "[0.1, 50, 5, {'num_samples': 859, 'precision': 0.529, 'recall': 0.224, 'f_score': 0.315}]\n",
      "[0.2, 5, 1, {'num_samples': 859, 'precision': 0.513, 'recall': 0.218, 'f_score': 0.306}]\n",
      "[0.2, 5, 2, {'num_samples': 859, 'precision': 0.38, 'recall': 0.161, 'f_score': 0.226}]\n",
      "[0.2, 5, 3, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.2, 5, 4, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.2, 5, 5, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.2, 10, 1, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.2, 10, 2, {'num_samples': 859, 'precision': 0.519, 'recall': 0.22, 'f_score': 0.309}]\n",
      "[0.2, 10, 3, {'num_samples': 859, 'precision': 0.446, 'recall': 0.189, 'f_score': 0.266}]\n",
      "[0.2, 10, 4, {'num_samples': 859, 'precision': 0.371, 'recall': 0.158, 'f_score': 0.221}]\n",
      "[0.2, 10, 5, {'num_samples': 859, 'precision': 0.332, 'recall': 0.141, 'f_score': 0.198}]\n",
      "[0.2, 15, 1, {'num_samples': 859, 'precision': 0.708, 'recall': 0.3, 'f_score': 0.422}]\n",
      "[0.2, 15, 2, {'num_samples': 859, 'precision': 0.602, 'recall': 0.255, 'f_score': 0.359}]\n",
      "[0.2, 15, 3, {'num_samples': 859, 'precision': 0.519, 'recall': 0.22, 'f_score': 0.309}]\n",
      "[0.2, 15, 4, {'num_samples': 859, 'precision': 0.463, 'recall': 0.197, 'f_score': 0.276}]\n",
      "[0.2, 15, 5, {'num_samples': 859, 'precision': 0.434, 'recall': 0.184, 'f_score': 0.259}]\n",
      "[0.2, 20, 1, {'num_samples': 859, 'precision': 0.698, 'recall': 0.296, 'f_score': 0.416}]\n",
      "[0.2, 20, 2, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.2, 20, 3, {'num_samples': 859, 'precision': 0.584, 'recall': 0.248, 'f_score': 0.348}]\n",
      "[0.2, 20, 4, {'num_samples': 859, 'precision': 0.52, 'recall': 0.221, 'f_score': 0.31}]\n",
      "[0.2, 20, 5, {'num_samples': 859, 'precision': 0.473, 'recall': 0.2, 'f_score': 0.282}]\n",
      "[0.2, 25, 1, {'num_samples': 859, 'precision': 0.692, 'recall': 0.293, 'f_score': 0.412}]\n",
      "[0.2, 25, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.2, 25, 3, {'num_samples': 859, 'precision': 0.639, 'recall': 0.271, 'f_score': 0.381}]\n",
      "[0.2, 25, 4, {'num_samples': 859, 'precision': 0.577, 'recall': 0.245, 'f_score': 0.344}]\n",
      "[0.2, 25, 5, {'num_samples': 859, 'precision': 0.527, 'recall': 0.224, 'f_score': 0.314}]\n",
      "[0.2, 30, 1, {'num_samples': 859, 'precision': 0.688, 'recall': 0.292, 'f_score': 0.41}]\n",
      "[0.2, 30, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.2, 30, 3, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.2, 30, 4, {'num_samples': 859, 'precision': 0.618, 'recall': 0.262, 'f_score': 0.368}]\n",
      "[0.2, 30, 5, {'num_samples': 859, 'precision': 0.576, 'recall': 0.244, 'f_score': 0.343}]\n",
      "[0.2, 35, 1, {'num_samples': 859, 'precision': 0.68, 'recall': 0.288, 'f_score': 0.405}]\n",
      "[0.2, 35, 2, {'num_samples': 859, 'precision': 0.68, 'recall': 0.288, 'f_score': 0.405}]\n",
      "[0.2, 35, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.2, 35, 4, {'num_samples': 859, 'precision': 0.638, 'recall': 0.271, 'f_score': 0.38}]\n",
      "[0.2, 35, 5, {'num_samples': 859, 'precision': 0.609, 'recall': 0.258, 'f_score': 0.363}]\n",
      "[0.2, 40, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.2, 40, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.2, 40, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.2, 40, 4, {'num_samples': 859, 'precision': 0.652, 'recall': 0.277, 'f_score': 0.388}]\n",
      "[0.2, 40, 5, {'num_samples': 859, 'precision': 0.631, 'recall': 0.268, 'f_score': 0.376}]\n",
      "[0.2, 45, 1, {'num_samples': 859, 'precision': 0.659, 'recall': 0.28, 'f_score': 0.393}]\n",
      "[0.2, 45, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.2, 45, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.2, 45, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.2, 45, 5, {'num_samples': 859, 'precision': 0.645, 'recall': 0.274, 'f_score': 0.384}]\n",
      "[0.2, 50, 1, {'num_samples': 859, 'precision': 0.653, 'recall': 0.277, 'f_score': 0.389}]\n",
      "[0.2, 50, 2, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.2, 50, 3, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.2, 50, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.2, 50, 5, {'num_samples': 859, 'precision': 0.655, 'recall': 0.278, 'f_score': 0.39}]\n",
      "[0.30000000000000004, 5, 1, {'num_samples': 859, 'precision': 0.591, 'recall': 0.251, 'f_score': 0.352}]\n",
      "[0.30000000000000004, 5, 2, {'num_samples': 859, 'precision': 0.46, 'recall': 0.195, 'f_score': 0.274}]\n",
      "[0.30000000000000004, 5, 3, {'num_samples': 859, 'precision': 0.38, 'recall': 0.161, 'f_score': 0.226}]\n",
      "[0.30000000000000004, 5, 4, {'num_samples': 859, 'precision': 0.332, 'recall': 0.141, 'f_score': 0.198}]\n",
      "[0.30000000000000004, 5, 5, {'num_samples': 859, 'precision': 0.331, 'recall': 0.14, 'f_score': 0.197}]\n",
      "[0.30000000000000004, 10, 1, {'num_samples': 859, 'precision': 0.711, 'recall': 0.302, 'f_score': 0.424}]\n",
      "[0.30000000000000004, 10, 2, {'num_samples': 859, 'precision': 0.603, 'recall': 0.256, 'f_score': 0.359}]\n",
      "[0.30000000000000004, 10, 3, {'num_samples': 859, 'precision': 0.52, 'recall': 0.221, 'f_score': 0.31}]\n",
      "[0.30000000000000004, 10, 4, {'num_samples': 859, 'precision': 0.464, 'recall': 0.197, 'f_score': 0.277}]\n",
      "[0.30000000000000004, 10, 5, {'num_samples': 859, 'precision': 0.427, 'recall': 0.181, 'f_score': 0.255}]\n",
      "[0.30000000000000004, 15, 1, {'num_samples': 859, 'precision': 0.703, 'recall': 0.298, 'f_score': 0.419}]\n",
      "[0.30000000000000004, 15, 2, {'num_samples': 859, 'precision': 0.687, 'recall': 0.291, 'f_score': 0.409}]\n",
      "[0.30000000000000004, 15, 3, {'num_samples': 859, 'precision': 0.612, 'recall': 0.26, 'f_score': 0.365}]\n",
      "[0.30000000000000004, 15, 4, {'num_samples': 859, 'precision': 0.542, 'recall': 0.23, 'f_score': 0.323}]\n",
      "[0.30000000000000004, 15, 5, {'num_samples': 859, 'precision': 0.511, 'recall': 0.217, 'f_score': 0.304}]\n",
      "[0.30000000000000004, 20, 1, {'num_samples': 859, 'precision': 0.687, 'recall': 0.291, 'f_score': 0.409}]\n",
      "[0.30000000000000004, 20, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.30000000000000004, 20, 3, {'num_samples': 859, 'precision': 0.66, 'recall': 0.28, 'f_score': 0.393}]\n",
      "[0.30000000000000004, 20, 4, {'num_samples': 859, 'precision': 0.616, 'recall': 0.261, 'f_score': 0.367}]\n",
      "[0.30000000000000004, 20, 5, {'num_samples': 859, 'precision': 0.574, 'recall': 0.243, 'f_score': 0.342}]\n",
      "[0.30000000000000004, 25, 1, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.30000000000000004, 25, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.30000000000000004, 25, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.30000000000000004, 25, 4, {'num_samples': 859, 'precision': 0.646, 'recall': 0.274, 'f_score': 0.385}]\n",
      "[0.30000000000000004, 25, 5, {'num_samples': 859, 'precision': 0.622, 'recall': 0.264, 'f_score': 0.37}]\n",
      "[0.30000000000000004, 30, 1, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.30000000000000004, 30, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.30000000000000004, 30, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.30000000000000004, 30, 4, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.30000000000000004, 30, 5, {'num_samples': 859, 'precision': 0.643, 'recall': 0.273, 'f_score': 0.383}]\n",
      "[0.30000000000000004, 35, 1, {'num_samples': 859, 'precision': 0.654, 'recall': 0.278, 'f_score': 0.39}]\n",
      "[0.30000000000000004, 35, 2, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.30000000000000004, 35, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.30000000000000004, 35, 4, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.30000000000000004, 35, 5, {'num_samples': 859, 'precision': 0.657, 'recall': 0.279, 'f_score': 0.391}]\n",
      "[0.30000000000000004, 40, 1, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.30000000000000004, 40, 2, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.30000000000000004, 40, 3, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.30000000000000004, 40, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.30000000000000004, 40, 5, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.30000000000000004, 45, 1, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.30000000000000004, 45, 2, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.30000000000000004, 45, 3, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.30000000000000004, 45, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.30000000000000004, 45, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.30000000000000004, 50, 1, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.30000000000000004, 50, 2, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.30000000000000004, 50, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.30000000000000004, 50, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.30000000000000004, 50, 5, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.4, 5, 1, {'num_samples': 859, 'precision': 0.647, 'recall': 0.275, 'f_score': 0.386}]\n",
      "[0.4, 5, 2, {'num_samples': 859, 'precision': 0.513, 'recall': 0.218, 'f_score': 0.306}]\n",
      "[0.4, 5, 3, {'num_samples': 859, 'precision': 0.44, 'recall': 0.187, 'f_score': 0.262}]\n",
      "[0.4, 5, 4, {'num_samples': 859, 'precision': 0.375, 'recall': 0.159, 'f_score': 0.223}]\n",
      "[0.4, 5, 5, {'num_samples': 859, 'precision': 0.333, 'recall': 0.141, 'f_score': 0.198}]\n",
      "[0.4, 10, 1, {'num_samples': 859, 'precision': 0.711, 'recall': 0.302, 'f_score': 0.424}]\n",
      "[0.4, 10, 2, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.4, 10, 3, {'num_samples': 859, 'precision': 0.576, 'recall': 0.244, 'f_score': 0.343}]\n",
      "[0.4, 10, 4, {'num_samples': 859, 'precision': 0.517, 'recall': 0.219, 'f_score': 0.308}]\n",
      "[0.4, 10, 5, {'num_samples': 859, 'precision': 0.468, 'recall': 0.199, 'f_score': 0.279}]\n",
      "[0.4, 15, 1, {'num_samples': 859, 'precision': 0.69, 'recall': 0.293, 'f_score': 0.411}]\n",
      "[0.4, 15, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.4, 15, 3, {'num_samples': 859, 'precision': 0.658, 'recall': 0.279, 'f_score': 0.392}]\n",
      "[0.4, 15, 4, {'num_samples': 859, 'precision': 0.62, 'recall': 0.263, 'f_score': 0.37}]\n",
      "[0.4, 15, 5, {'num_samples': 859, 'precision': 0.574, 'recall': 0.243, 'f_score': 0.342}]\n",
      "[0.4, 20, 1, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.4, 20, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.4, 20, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.4, 20, 4, {'num_samples': 859, 'precision': 0.654, 'recall': 0.278, 'f_score': 0.39}]\n",
      "[0.4, 20, 5, {'num_samples': 859, 'precision': 0.63, 'recall': 0.267, 'f_score': 0.375}]\n",
      "[0.4, 25, 1, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 25, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.4, 25, 3, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 25, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 25, 5, {'num_samples': 859, 'precision': 0.654, 'recall': 0.278, 'f_score': 0.39}]\n",
      "[0.4, 30, 1, {'num_samples': 859, 'precision': 0.659, 'recall': 0.28, 'f_score': 0.393}]\n",
      "[0.4, 30, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.4, 30, 3, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.4, 30, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.4, 30, 5, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 35, 1, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.4, 35, 2, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.4, 35, 3, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 35, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.4, 35, 5, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.4, 40, 1, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.4, 40, 2, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.4, 40, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.4, 40, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.4, 40, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.4, 45, 1, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.4, 45, 2, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.4, 45, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.4, 45, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.4, 45, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.4, 50, 1, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.4, 50, 2, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.4, 50, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.4, 50, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.4, 50, 5, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 5, 1, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.5, 5, 2, {'num_samples': 859, 'precision': 0.547, 'recall': 0.232, 'f_score': 0.326}]\n",
      "[0.5, 5, 3, {'num_samples': 859, 'precision': 0.469, 'recall': 0.199, 'f_score': 0.279}]\n",
      "[0.5, 5, 4, {'num_samples': 859, 'precision': 0.432, 'recall': 0.183, 'f_score': 0.257}]\n",
      "[0.5, 5, 5, {'num_samples': 859, 'precision': 0.374, 'recall': 0.159, 'f_score': 0.223}]\n",
      "[0.5, 10, 1, {'num_samples': 859, 'precision': 0.711, 'recall': 0.302, 'f_score': 0.424}]\n",
      "[0.5, 10, 2, {'num_samples': 859, 'precision': 0.694, 'recall': 0.294, 'f_score': 0.413}]\n",
      "[0.5, 10, 3, {'num_samples': 859, 'precision': 0.63, 'recall': 0.267, 'f_score': 0.375}]\n",
      "[0.5, 10, 4, {'num_samples': 859, 'precision': 0.566, 'recall': 0.24, 'f_score': 0.337}]\n",
      "[0.5, 10, 5, {'num_samples': 859, 'precision': 0.519, 'recall': 0.22, 'f_score': 0.309}]\n",
      "[0.5, 15, 1, {'num_samples': 859, 'precision': 0.688, 'recall': 0.292, 'f_score': 0.41}]\n",
      "[0.5, 15, 2, {'num_samples': 859, 'precision': 0.686, 'recall': 0.291, 'f_score': 0.408}]\n",
      "[0.5, 15, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 15, 4, {'num_samples': 859, 'precision': 0.641, 'recall': 0.272, 'f_score': 0.382}]\n",
      "[0.5, 15, 5, {'num_samples': 859, 'precision': 0.619, 'recall': 0.263, 'f_score': 0.369}]\n",
      "[0.5, 20, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 20, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.5, 20, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.5, 20, 4, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 20, 5, {'num_samples': 859, 'precision': 0.652, 'recall': 0.277, 'f_score': 0.388}]\n",
      "[0.5, 25, 1, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.5, 25, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 25, 3, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.5, 25, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.5, 25, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 30, 1, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.5, 30, 2, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 30, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 30, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.5, 30, 5, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.5, 35, 1, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.5, 35, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 35, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.5, 35, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.5, 35, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 40, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 40, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.5, 40, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.5, 40, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.5, 40, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 45, 1, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.5, 45, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.5, 45, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.5, 45, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.5, 45, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 50, 1, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.5, 50, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.5, 50, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 50, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.5, 50, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 5, 1, {'num_samples': 859, 'precision': 0.711, 'recall': 0.302, 'f_score': 0.424}]\n",
      "[0.6000000000000001, 5, 2, {'num_samples': 859, 'precision': 0.588, 'recall': 0.249, 'f_score': 0.35}]\n",
      "[0.6000000000000001, 5, 3, {'num_samples': 859, 'precision': 0.513, 'recall': 0.218, 'f_score': 0.306}]\n",
      "[0.6000000000000001, 5, 4, {'num_samples': 859, 'precision': 0.46, 'recall': 0.195, 'f_score': 0.274}]\n",
      "[0.6000000000000001, 5, 5, {'num_samples': 859, 'precision': 0.419, 'recall': 0.178, 'f_score': 0.25}]\n",
      "[0.6000000000000001, 10, 1, {'num_samples': 859, 'precision': 0.707, 'recall': 0.3, 'f_score': 0.421}]\n",
      "[0.6000000000000001, 10, 2, {'num_samples': 859, 'precision': 0.683, 'recall': 0.29, 'f_score': 0.407}]\n",
      "[0.6000000000000001, 10, 3, {'num_samples': 859, 'precision': 0.654, 'recall': 0.278, 'f_score': 0.39}]\n",
      "[0.6000000000000001, 10, 4, {'num_samples': 859, 'precision': 0.61, 'recall': 0.259, 'f_score': 0.363}]\n",
      "[0.6000000000000001, 10, 5, {'num_samples': 859, 'precision': 0.569, 'recall': 0.241, 'f_score': 0.339}]\n",
      "[0.6000000000000001, 15, 1, {'num_samples': 859, 'precision': 0.685, 'recall': 0.29, 'f_score': 0.408}]\n",
      "[0.6000000000000001, 15, 2, {'num_samples': 859, 'precision': 0.68, 'recall': 0.288, 'f_score': 0.405}]\n",
      "[0.6000000000000001, 15, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 15, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.6000000000000001, 15, 5, {'num_samples': 859, 'precision': 0.644, 'recall': 0.273, 'f_score': 0.383}]\n",
      "[0.6000000000000001, 20, 1, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.6000000000000001, 20, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.6000000000000001, 20, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.6000000000000001, 20, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.6000000000000001, 20, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 25, 1, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.6000000000000001, 25, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.6000000000000001, 25, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 25, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.6000000000000001, 25, 5, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.6000000000000001, 30, 1, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.6000000000000001, 30, 2, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.6000000000000001, 30, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.6000000000000001, 30, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.6000000000000001, 30, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.6000000000000001, 35, 1, {'num_samples': 859, 'precision': 0.659, 'recall': 0.28, 'f_score': 0.393}]\n",
      "[0.6000000000000001, 35, 2, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 35, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 35, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.6000000000000001, 35, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 40, 1, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.6000000000000001, 40, 2, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.6000000000000001, 40, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 40, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.6000000000000001, 40, 5, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 45, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 45, 2, {'num_samples': 859, 'precision': 0.676, 'recall': 0.287, 'f_score': 0.403}]\n",
      "[0.6000000000000001, 45, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.6000000000000001, 45, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.6000000000000001, 45, 5, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.6000000000000001, 50, 1, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.6000000000000001, 50, 2, {'num_samples': 859, 'precision': 0.676, 'recall': 0.287, 'f_score': 0.403}]\n",
      "[0.6000000000000001, 50, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.6000000000000001, 50, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.6000000000000001, 50, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.7000000000000001, 5, 1, {'num_samples': 859, 'precision': 0.715, 'recall': 0.303, 'f_score': 0.426}]\n",
      "[0.7000000000000001, 5, 2, {'num_samples': 859, 'precision': 0.634, 'recall': 0.269, 'f_score': 0.378}]\n",
      "[0.7000000000000001, 5, 3, {'num_samples': 859, 'precision': 0.542, 'recall': 0.23, 'f_score': 0.323}]\n",
      "[0.7000000000000001, 5, 4, {'num_samples': 859, 'precision': 0.485, 'recall': 0.206, 'f_score': 0.289}]\n",
      "[0.7000000000000001, 5, 5, {'num_samples': 859, 'precision': 0.446, 'recall': 0.189, 'f_score': 0.266}]\n",
      "[0.7000000000000001, 10, 1, {'num_samples': 859, 'precision': 0.701, 'recall': 0.297, 'f_score': 0.417}]\n",
      "[0.7000000000000001, 10, 2, {'num_samples': 859, 'precision': 0.694, 'recall': 0.294, 'f_score': 0.413}]\n",
      "[0.7000000000000001, 10, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 10, 4, {'num_samples': 859, 'precision': 0.641, 'recall': 0.272, 'f_score': 0.382}]\n",
      "[0.7000000000000001, 10, 5, {'num_samples': 859, 'precision': 0.6, 'recall': 0.254, 'f_score': 0.357}]\n",
      "[0.7000000000000001, 15, 1, {'num_samples': 859, 'precision': 0.695, 'recall': 0.295, 'f_score': 0.414}]\n",
      "[0.7000000000000001, 15, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 15, 3, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 15, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 15, 5, {'num_samples': 859, 'precision': 0.653, 'recall': 0.277, 'f_score': 0.389}]\n",
      "[0.7000000000000001, 20, 1, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.7000000000000001, 20, 2, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.7000000000000001, 20, 3, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.7000000000000001, 20, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.7000000000000001, 20, 5, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 25, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 25, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 25, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 25, 4, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.7000000000000001, 25, 5, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 30, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 30, 2, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 30, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.7000000000000001, 30, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.7000000000000001, 30, 5, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.7000000000000001, 35, 1, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 35, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 35, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 35, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.7000000000000001, 35, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.7000000000000001, 40, 1, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.7000000000000001, 40, 2, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 40, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.7000000000000001, 40, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.7000000000000001, 40, 5, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 45, 1, {'num_samples': 859, 'precision': 0.657, 'recall': 0.279, 'f_score': 0.391}]\n",
      "[0.7000000000000001, 45, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 45, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 45, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.7000000000000001, 45, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.7000000000000001, 50, 1, {'num_samples': 859, 'precision': 0.658, 'recall': 0.279, 'f_score': 0.392}]\n",
      "[0.7000000000000001, 50, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.7000000000000001, 50, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.7000000000000001, 50, 4, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.7000000000000001, 50, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 5, 1, {'num_samples': 859, 'precision': 0.718, 'recall': 0.305, 'f_score': 0.428}]\n",
      "[0.8, 5, 2, {'num_samples': 859, 'precision': 0.658, 'recall': 0.279, 'f_score': 0.392}]\n",
      "[0.8, 5, 3, {'num_samples': 859, 'precision': 0.57, 'recall': 0.242, 'f_score': 0.34}]\n",
      "[0.8, 5, 4, {'num_samples': 859, 'precision': 0.518, 'recall': 0.22, 'f_score': 0.309}]\n",
      "[0.8, 5, 5, {'num_samples': 859, 'precision': 0.463, 'recall': 0.197, 'f_score': 0.276}]\n",
      "[0.8, 10, 1, {'num_samples': 859, 'precision': 0.69, 'recall': 0.293, 'f_score': 0.411}]\n",
      "[0.8, 10, 2, {'num_samples': 859, 'precision': 0.686, 'recall': 0.291, 'f_score': 0.408}]\n",
      "[0.8, 10, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.8, 10, 4, {'num_samples': 859, 'precision': 0.65, 'recall': 0.276, 'f_score': 0.387}]\n",
      "[0.8, 10, 5, {'num_samples': 859, 'precision': 0.625, 'recall': 0.265, 'f_score': 0.372}]\n",
      "[0.8, 15, 1, {'num_samples': 859, 'precision': 0.683, 'recall': 0.29, 'f_score': 0.407}]\n",
      "[0.8, 15, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.8, 15, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.8, 15, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.8, 15, 5, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.8, 20, 1, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.8, 20, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.8, 20, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 20, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[0.8, 20, 5, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.8, 25, 1, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.8, 25, 2, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.8, 25, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.8, 25, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 25, 5, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 30, 1, {'num_samples': 859, 'precision': 0.676, 'recall': 0.287, 'f_score': 0.403}]\n",
      "[0.8, 30, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.8, 30, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.8, 30, 4, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 30, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.8, 35, 1, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.8, 35, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.8, 35, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.8, 35, 4, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.8, 35, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.8, 40, 1, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.8, 40, 2, {'num_samples': 859, 'precision': 0.683, 'recall': 0.29, 'f_score': 0.407}]\n",
      "[0.8, 40, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.8, 40, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.8, 40, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.8, 45, 1, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.8, 45, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.8, 45, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.8, 45, 4, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.8, 45, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.8, 50, 1, {'num_samples': 859, 'precision': 0.661, 'recall': 0.28, 'f_score': 0.394}]\n",
      "[0.8, 50, 2, {'num_samples': 859, 'precision': 0.683, 'recall': 0.29, 'f_score': 0.407}]\n",
      "[0.8, 50, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.8, 50, 4, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.8, 50, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 5, 1, {'num_samples': 859, 'precision': 0.724, 'recall': 0.307, 'f_score': 0.431}]\n",
      "[0.9, 5, 2, {'num_samples': 859, 'precision': 0.676, 'recall': 0.287, 'f_score': 0.403}]\n",
      "[0.9, 5, 3, {'num_samples': 859, 'precision': 0.596, 'recall': 0.253, 'f_score': 0.355}]\n",
      "[0.9, 5, 4, {'num_samples': 859, 'precision': 0.537, 'recall': 0.228, 'f_score': 0.32}]\n",
      "[0.9, 5, 5, {'num_samples': 859, 'precision': 0.498, 'recall': 0.211, 'f_score': 0.297}]\n",
      "[0.9, 10, 1, {'num_samples': 859, 'precision': 0.7, 'recall': 0.297, 'f_score': 0.417}]\n",
      "[0.9, 10, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.9, 10, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.9, 10, 4, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.9, 10, 5, {'num_samples': 859, 'precision': 0.641, 'recall': 0.272, 'f_score': 0.382}]\n",
      "[0.9, 15, 1, {'num_samples': 859, 'precision': 0.693, 'recall': 0.294, 'f_score': 0.413}]\n",
      "[0.9, 15, 2, {'num_samples': 859, 'precision': 0.68, 'recall': 0.288, 'f_score': 0.405}]\n",
      "[0.9, 15, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.9, 15, 4, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.9, 15, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 20, 1, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.9, 20, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.9, 20, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.9, 20, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.9, 20, 5, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 25, 1, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.9, 25, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.9, 25, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 25, 4, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.9, 25, 5, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.9, 30, 1, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 30, 2, {'num_samples': 859, 'precision': 0.682, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.9, 30, 3, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 30, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.9, 30, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.9, 35, 1, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.9, 35, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.9, 35, 3, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.9, 35, 4, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[0.9, 35, 5, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[0.9, 40, 1, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[0.9, 40, 2, {'num_samples': 859, 'precision': 0.688, 'recall': 0.292, 'f_score': 0.41}]\n",
      "[0.9, 40, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.9, 40, 4, {'num_samples': 859, 'precision': 0.662, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[0.9, 40, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 45, 1, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[0.9, 45, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.9, 45, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[0.9, 45, 4, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.9, 45, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[0.9, 50, 1, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[0.9, 50, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[0.9, 50, 3, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[0.9, 50, 4, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[0.9, 50, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[1.0, 5, 1, {'num_samples': 859, 'precision': 0.732, 'recall': 0.311, 'f_score': 0.436}]\n",
      "[1.0, 5, 2, {'num_samples': 859, 'precision': 0.692, 'recall': 0.293, 'f_score': 0.412}]\n",
      "[1.0, 5, 3, {'num_samples': 859, 'precision': 0.622, 'recall': 0.264, 'f_score': 0.37}]\n",
      "[1.0, 5, 4, {'num_samples': 859, 'precision': 0.561, 'recall': 0.238, 'f_score': 0.334}]\n",
      "[1.0, 5, 5, {'num_samples': 859, 'precision': 0.513, 'recall': 0.218, 'f_score': 0.306}]\n",
      "[1.0, 10, 1, {'num_samples': 859, 'precision': 0.702, 'recall': 0.298, 'f_score': 0.418}]\n",
      "[1.0, 10, 2, {'num_samples': 859, 'precision': 0.685, 'recall': 0.29, 'f_score': 0.408}]\n",
      "[1.0, 10, 3, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 10, 4, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[1.0, 10, 5, {'num_samples': 859, 'precision': 0.65, 'recall': 0.276, 'f_score': 0.387}]\n",
      "[1.0, 15, 1, {'num_samples': 859, 'precision': 0.683, 'recall': 0.29, 'f_score': 0.407}]\n",
      "[1.0, 15, 2, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[1.0, 15, 3, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[1.0, 15, 4, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[1.0, 15, 5, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 20, 1, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[1.0, 20, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[1.0, 20, 3, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[1.0, 20, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[1.0, 20, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[1.0, 25, 1, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 25, 2, {'num_samples': 859, 'precision': 0.681, 'recall': 0.289, 'f_score': 0.406}]\n",
      "[1.0, 25, 3, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[1.0, 25, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[1.0, 25, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[1.0, 30, 1, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 30, 2, {'num_samples': 859, 'precision': 0.674, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 30, 3, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[1.0, 30, 4, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[1.0, 30, 5, {'num_samples': 859, 'precision': 0.668, 'recall': 0.283, 'f_score': 0.398}]\n",
      "[1.0, 35, 1, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 35, 2, {'num_samples': 859, 'precision': 0.679, 'recall': 0.288, 'f_score': 0.404}]\n",
      "[1.0, 35, 3, {'num_samples': 859, 'precision': 0.675, 'recall': 0.286, 'f_score': 0.402}]\n",
      "[1.0, 35, 4, {'num_samples': 859, 'precision': 0.665, 'recall': 0.282, 'f_score': 0.396}]\n",
      "[1.0, 35, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[1.0, 40, 1, {'num_samples': 859, 'precision': 0.664, 'recall': 0.281, 'f_score': 0.395}]\n",
      "[1.0, 40, 2, {'num_samples': 859, 'precision': 0.685, 'recall': 0.29, 'f_score': 0.408}]\n",
      "[1.0, 40, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[1.0, 40, 4, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[1.0, 40, 5, {'num_samples': 859, 'precision': 0.667, 'recall': 0.283, 'f_score': 0.397}]\n",
      "[1.0, 45, 1, {'num_samples': 859, 'precision': 0.666, 'recall': 0.282, 'f_score': 0.397}]\n",
      "[1.0, 45, 2, {'num_samples': 859, 'precision': 0.688, 'recall': 0.292, 'f_score': 0.41}]\n",
      "[1.0, 45, 3, {'num_samples': 859, 'precision': 0.678, 'recall': 0.287, 'f_score': 0.404}]\n",
      "[1.0, 45, 4, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[1.0, 45, 5, {'num_samples': 859, 'precision': 0.672, 'recall': 0.285, 'f_score': 0.4}]\n",
      "[1.0, 50, 1, {'num_samples': 859, 'precision': 0.669, 'recall': 0.284, 'f_score': 0.399}]\n",
      "[1.0, 50, 2, {'num_samples': 859, 'precision': 0.685, 'recall': 0.29, 'f_score': 0.408}]\n",
      "[1.0, 50, 3, {'num_samples': 859, 'precision': 0.676, 'recall': 0.287, 'f_score': 0.403}]\n",
      "[1.0, 50, 4, {'num_samples': 859, 'precision': 0.673, 'recall': 0.285, 'f_score': 0.401}]\n",
      "[1.0, 50, 5, {'num_samples': 859, 'precision': 0.671, 'recall': 0.284, 'f_score': 0.399}]\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = []\n",
    "for i in scores:\n",
    "    ff.append(i[3]['f_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.436"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 5, 1, {'num_samples': 859, 'precision': 0.732, 'recall': 0.311, 'f_score': 0.436}]\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    if(i[3]['f_score'] == 0.436):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "reca = []\n",
    "for i in scores:\n",
    "    reca.append(i[3]['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.311"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(reca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 5, 1, {'num_samples': 859, 'precision': 0.732, 'recall': 0.311, 'f_score': 0.436}]\n"
     ]
    }
   ],
   "source": [
    "for i in scores:\n",
    "    if(i[3]['recall'] == 0.311):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "n=WordNetLemmatizer()\n",
    "\n",
    "def prep(text):\n",
    "    \n",
    "    shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "    text = shortword.sub('', text)\n",
    "    text = re.sub(r'[?|!|\\'|\"|#|_]', '', text)\n",
    "    text = re.sub(r'[,|.|;|:|(|)|{|}|\\|/|<|>]|-', ' ', text)\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub('[^a-z A-Z]+', ' ', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    \n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = [n.lemmatize(w) for w in text]\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['zero','one','two','three','four','five','six','seven','eight','nine','ten',\n",
    "                       'may','also','across','among','beside','however','yet','within',\n",
    "                      'integer', 'number', 'contain', 'line', 'first'])\n",
    "    result = []\n",
    "    for w in text: \n",
    "        if w not in stop_words: \n",
    "            result.append(w) \n",
    "    text = ' '.join(result)\n",
    "    \n",
    "    return text\n",
    "hi = '''\n",
    "Bob is playing a game of Spaceship Solitaire. The goal of this game is to build a spaceship. In order to do this, he first needs to accumulate enough resources for the construction. There are 𝑛 types of resources, numbered 1 through 𝑛. Bob needs at least 𝑎𝑖 pieces of the 𝑖-th resource to build the spaceship. The number 𝑎𝑖 is called the goal for resource 𝑖.\n",
    "\n",
    "Each resource takes 1 turn to produce and in each turn only one resource can be produced. However, there are certain milestones that speed up production. Every milestone is a triple (𝑠𝑗,𝑡𝑗,𝑢𝑗), meaning that as soon as Bob has 𝑡𝑗 units of the resource 𝑠𝑗, he receives one unit of the resource 𝑢𝑗 for free, without him needing to spend a turn. It is possible that getting this free resource allows Bob to claim reward for another milestone. This way, he can obtain a large number of resources in a single turn.\n",
    "\n",
    "The game is constructed in such a way that there are never two milestones that have the same 𝑠𝑗 and 𝑡𝑗, that is, the award for reaching 𝑡𝑗 units of resource 𝑠𝑗 is at most one additional resource.\n",
    "\n",
    "A bonus is never awarded for 0 of any resource, neither for reaching the goal 𝑎𝑖 nor for going past the goal — formally, for every milestone 0<𝑡𝑗<𝑎𝑠𝑗.\n",
    "\n",
    "A bonus for reaching certain amount of a resource can be the resource itself, that is, 𝑠𝑗=𝑢𝑗.\n",
    "\n",
    "Initially there are no milestones. You are to process 𝑞 updates, each of which adds, removes or modifies a milestone. After every update, output the minimum number of turns needed to finish the game, that is, to accumulate at least 𝑎𝑖 of 𝑖-th resource for each 𝑖∈[1,𝑛].\n",
    "\n",
    "Input\n",
    "The first line contains a single integer 𝑛 (1≤𝑛≤2⋅105) — the number of types of resources.\n",
    "\n",
    "The second line contains 𝑛 space separated integers 𝑎1,𝑎2,…,𝑎𝑛 (1≤𝑎𝑖≤109), the 𝑖-th of which is the goal for the 𝑖-th resource.\n",
    "\n",
    "The third line contains a single integer 𝑞 (1≤𝑞≤105) — the number of updates to the game milestones.\n",
    "\n",
    "Then 𝑞 lines follow, the 𝑗-th of which contains three space separated integers 𝑠𝑗, 𝑡𝑗, 𝑢𝑗 (1≤𝑠𝑗≤𝑛, 1≤𝑡𝑗<𝑎𝑠𝑗, 0≤𝑢𝑗≤𝑛). For each triple, perform the following actions:\n",
    "\n",
    "First, if there is already a milestone for obtaining 𝑡𝑗 units of resource 𝑠𝑗, it is removed.\n",
    "If 𝑢𝑗=0, no new milestone is added.\n",
    "If 𝑢𝑗≠0, add the following milestone: \"For reaching 𝑡𝑗 units of resource 𝑠𝑗, gain one free piece of 𝑢𝑗.\"\n",
    "Output the minimum number of turns needed to win the game.\n",
    "Output\n",
    "Output 𝑞 lines, each consisting of a single integer, the 𝑖-th represents the answer after the 𝑖-th update.\n",
    "'''\n",
    "hi = prep(hi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dp': 0.508, 'greedy': 0.314}\n",
      "{'num_samples': 859, 'precision': 0.728, 'recall': 0.309, 'f_score': 0.433}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = fasttext.train_supervised(input=\"./Data/fasttext/train.txt\", lr=1.0,\\\n",
    "                                   epoch=5, wordNgrams=1, bucket=200000, dim=50, loss='ova')\n",
    "ft_obj = ImplementFastText()\n",
    "ft_obj.load_model(model)\n",
    "score = ft_obj.score()\n",
    "result = ft_obj.predict([hi], num_tags=2)\n",
    "print(result)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
